% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/text_core.R
\name{tokenize_files}
\alias{tokenize_files}
\title{tokenize_files}
\usage{
tokenize_files(
  files,
  path,
  output_dir,
  output_names = NULL,
  n_workers = 6,
  rules = NULL,
  tok = NULL,
  encoding = "utf8",
  skip_if_exists = FALSE
)
}
\arguments{
\item{files}{files}

\item{path}{path}

\item{output_dir}{output_dir}

\item{output_names}{output_names}

\item{n_workers}{n_workers}

\item{rules}{rules}

\item{tok}{tok}

\item{encoding}{encoding}

\item{skip_if_exists}{skip_if_exists}
}
\description{
Tokenize text `files` in parallel using `n_workers`
}
