<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />



<title>Text-summarization</title>

<script src="data:application/javascript;base64,Ly8gUGFuZG9jIDIuOSBhZGRzIGF0dHJpYnV0ZXMgb24gYm90aCBoZWFkZXIgYW5kIGRpdi4gV2UgcmVtb3ZlIHRoZSBmb3JtZXIgKHRvCi8vIGJlIGNvbXBhdGlibGUgd2l0aCB0aGUgYmVoYXZpb3Igb2YgUGFuZG9jIDwgMi44KS4KZG9jdW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignRE9NQ29udGVudExvYWRlZCcsIGZ1bmN0aW9uKGUpIHsKICB2YXIgaHMgPSBkb2N1bWVudC5xdWVyeVNlbGVjdG9yQWxsKCJkaXYuc2VjdGlvbltjbGFzcyo9J2xldmVsJ10gPiA6Zmlyc3QtY2hpbGQiKTsKICB2YXIgaSwgaCwgYTsKICBmb3IgKGkgPSAwOyBpIDwgaHMubGVuZ3RoOyBpKyspIHsKICAgIGggPSBoc1tpXTsKICAgIGlmICghL15oWzEtNl0kL2kudGVzdChoLnRhZ05hbWUpKSBjb250aW51ZTsgIC8vIGl0IHNob3VsZCBiZSBhIGhlYWRlciBoMS1oNgogICAgYSA9IGguYXR0cmlidXRlczsKICAgIHdoaWxlIChhLmxlbmd0aCA+IDApIGgucmVtb3ZlQXR0cmlidXRlKGFbMF0ubmFtZSk7CiAgfQp9KTsK"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<link rel="stylesheet" href="data:text/css,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0A%7D%0Apre%20%7B%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" type="text/css" />




</head>

<body>




<h1 class="title toc-ignore">Text-summarization</h1>



<div id="intro" class="section level2">
<h2>Intro</h2>
<p>First, we need to install <code>blurr module</code> for <a href="https://github.com/huggingface/transformers">Transformers</a> integration.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>reticulate<span class="sc">::</span><span class="fu">py_install</span>(<span class="st">&#39;ohmeow-blurr&#39;</span>,<span class="at">pip =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
</div>
<div id="dataset" class="section level2">
<h2>Dataset</h2>
<p>Get dataset from the link:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(fastai)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(magrittr)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(zeallot)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>cnndm_df <span class="ot">=</span> data.table<span class="sc">::</span><span class="fu">fread</span>(<span class="st">&#39;https://raw.githubusercontent.com/ohmeow/blurr/master/nbs/cnndm_sample.csv&#39;</span>)</span></code></pre></div>
</div>
<div id="pretrained-model" class="section level2">
<h2>Pretrained model</h2>
<p>Get pretrained BART model from <code>transformers</code>:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>transformers <span class="ot">=</span> <span class="fu">transformers</span>()</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>BartForConditionalGeneration <span class="ot">=</span> transformers<span class="sc">$</span>BartForConditionalGeneration</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>pretrained_model_name <span class="ot">=</span> <span class="st">&quot;facebook/bart-large-cnn&quot;</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(hf_arch, hf_config, hf_tokenizer, hf_model) <span class="sc">%&lt;-%</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">get_hf_objects</span>(pretrained_model_name,<span class="at">model_cls=</span>BartForConditionalGeneration)</span></code></pre></div>
</div>
<div id="datablock" class="section level2">
<h2>Datablock</h2>
<p>Create datablock and see batch:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>before_batch_tfm <span class="ot">=</span> <span class="fu">HF_SummarizationBeforeBatchTransform</span>(hf_arch, </span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>                                                        hf_tokenizer, <span class="at">max_length=</span><span class="fu">c</span>(<span class="dv">256</span>, <span class="dv">130</span>))</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>blocks <span class="ot">=</span> <span class="fu">list</span>(<span class="fu">HF_Text2TextBlock</span>(<span class="at">before_batch_tfms=</span>before_batch_tfm, </span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>                                <span class="at">input_return_type=</span>HF_SummarizationInput), <span class="fu">noop</span>())</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>dblock <span class="ot">=</span> <span class="fu">DataBlock</span>(<span class="at">blocks=</span>blocks,</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>                   <span class="at">get_x=</span><span class="fu">ColReader</span>(<span class="st">&#39;article&#39;</span>),</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>                   <span class="at">get_y=</span><span class="fu">ColReader</span>(<span class="st">&#39;highlights&#39;</span>),</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>                   <span class="at">splitter=</span><span class="fu">RandomSplitter</span>())</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>dls <span class="ot">=</span> dblock <span class="sc">%&gt;%</span> <span class="fu">dataloaders</span>(cnndm_df, <span class="at">bs=</span><span class="dv">2</span>)</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>dls <span class="sc">%&gt;%</span> <span class="fu">one_batch</span>()</span></code></pre></div>
<pre><code>[[1]]
[[1]]$input_ids
tensor([[    0,    36, 16256,    43,   480,  2193,     7,    62,     7,   158,
           135,     9,    70,   684,  4707,     6,  1625,    16,  4984,    25,
            65,     9,     5,   144, 39865, 32273,  3806,    15,     5,  5518,
             4,    20,  9544,  3455,     9,  2147,   464,     8,  1050, 29779,
         26284,    15,  1632, 11534,    32,     6,   959,     6,  5608,     5,
          8066,     9,     5,   247,    18,  4066,  7892,     4,   178,    89,
            16,    10,   372,   432,     7,  2217,     4,    96,     5,   315,
          3076,  9356,  4928,    36,  4154,  9662,    43,   623, 12978, 23853,
          2521,    18,   889,     9, 10721,   625, 32273,   749,  1625,  5546,
           365,   212,     4,    20,   889,  3372,    10,   333,     9,   601,
           749,    14, 19655,     5,  1647,     9,     5,  3875,    18,  4707,
             8,    32,  3891,  1687,  2778, 39865, 32273,     4,  1740,    63,
         23491, 28919,    11,     5,  7599,  3939,     7,    63, 10602, 41166,
          1634,    11, 12718,  1115,   281,     8,     5,   854,  3964, 21785,
         14113,     8,    63, 38905,     8, 21950, 19947,    11,     5,  1926,
             6,  1625, 10902,    41,  5784,  4066,  3143,     9, 39456,     8,
           856, 25729,     4,   993,   195,  5243,    66,     9,   262,  1360,
         38950,  1848,  4707,   303,    11,  1625,   480,     5,   144,    11,
           143,   247,   480,    64,   129,    28, 13590,   624,    63,  7562,
             4,    85,    16,   184,     7, 39179,  3505,     9, 27772,     6,
         28482,  4707,     9,  7723,     6,   112,     6,  6115, 17576,     9,
          7723,     8,   973,     6,   151,  1380, 14868,     9,  3451,     4,
           221,  2839,  8367,   102,     6,    10,   786,    12,  7699,  1651,
            14,  1364,     7,  3720,  8360,     8,  5068,   709,    11,  1625,
             6,    34,  3919,   411,  4707,    61,    24,   161,  7648,  2072,
             5,  1272,  2713,    30,     5,     2],
        [    0,    36, 16256,    43,   480,  6871,    24,  1655, 22049,    50,
         41571,  1896,    54, 24509,    13,   244,     5,   363,     5,   601,
            12,   180,    12,   279,  1896,    21,   738,  1462,   116,   280,
           115,  6723,    15,    61,   985,     5,  3940,  2046,     4,  1868,
         22049,    18,     8,  1896,    18,  8826,  2327,   117, 28946,   273,
            11,  2559,   461,  4961,    25,     7,  1060, 28604,  2236,    16,
          1317, 11347,   148,    10,  7158,   486,    31,    14,   902,   973,
             6,  1125,     6,   363,    11, 23058,     6,  1261,    35,  4028,
            26,    24,    21,    69,   979,     4,   280, 34920,   480,    19,
          5767,  3809,  1243, 21605, 13875,    24,    21,    69,   979,     6,
         41571,     6,    54, 16670,    66,     6,   150, 15151,  2459, 22049,
            26,    24,    21,    69,   979,     6,  1655,     6,    54,    21,
         16600,    71,   145,  4487,    30,     5,  6066,   480,    21,  1353,
             7,   273,    18,   461,  7069,     6,     8,  1353,     7,     5,
           200,    12,  5743,  1900,   403, 25451,    11,  1353,  1261,     4,
         22049,    34,  4407,    45,  2181,     8,  1695,    37,   738,     5,
          7044,    11,  1403,    12, 21409,     4,    20,  7158,   486,   702,
          2330,    11,   461,    15,   273,     6,    39,  3969,  2026,     6,
           124,    62,    49, 19395,    14,    24,    21,  1896,     6,     8,
            45,    49,  3653,     6,    54,    21,     5, 29593,   368,     4,
          4500,  4945,   628,   273,  1390,     6, 15151,  2459, 22049,    26,
            79,    21,   686,  1655,    21,     5,    65, 16600,     4,  2612,
           116, 41039, 10105,    37,    18,   127,   979, 39732,   264,  7173,
         41039,  1250,     9,     5,  1065, 48149,    77,   553,   549,    79,
            56,   655,   137,  1317,    69,  1655, 22049,  7923, 24120,    50,
          8930,    66,    13,   244,     4,     2]], device=&#39;cuda:0&#39;)

[[1]]$attention_mask
tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device=&#39;cuda:0&#39;)

[[1]]$decoder_input_ids
tensor([[    0,  1625,  4452,     7,    62,     7,   158,   135,     9,    70,
           684,  4707,    15,  3875,   479, 50118,   243,    16,   184,     7,
         39179,  3505,     9, 27772,     6, 28482,  5103,  4707,     8,   973,
             6,   151,  3505,     9,  3451,   479, 50118, 33837,   709,     8,
          2147,   464,    16,  9405,    10,   380,  8793,    15,    63, 28809,
           479, 50118,   133,  3274,  9587,    16,   223,  1856,    11, 14117,
             9,   145,     5,   247,    18,   632,  7648,   479,     2,     1,
             1,     1,     1,     1,     1,     1],
        [    0,  5178,    35,    83,  1443,  2470,   161,    97,  1283,     6,
            45,     5,  7158,   486,     6,    40,  3094,     5,   403,   479,
         50118,  5341,    35,    83,  2470,    13,  1896,    18,   284,   161,
            37,  4265,     5,  3940,    40,   465, 22049,  2181,   479, 50118,
           534, 15356,  2459, 22049,   161,    79,  2215,     5, 28604,  2236,
            16,    14,     9,    69,   979,   479, 50118, 30541,     6, 41571,
          1896,    18, 18631,  1843,    26,    14,    24,    69,   979,    18,
          2236,    15,     5,  7158,   486,   479]], device=&#39;cuda:0&#39;)

[[1]]$labels
tensor([[ 1625,  4452,     7,    62,     7,   158,   135,     9,    70,   684,
          4707,    15,  3875,   479, 50118,   243,    16,   184,     7, 39179,
          3505,     9, 27772,     6, 28482,  5103,  4707,     8,   973,     6,
           151,  3505,     9,  3451,   479, 50118, 33837,   709,     8,  2147,
           464,    16,  9405,    10,   380,  8793,    15,    63, 28809,   479,
         50118,   133,  3274,  9587,    16,   223,  1856,    11, 14117,     9,
           145,     5,   247,    18,   632,  7648,   479,     2,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100],
        [ 5178,    35,    83,  1443,  2470,   161,    97,  1283,     6,    45,
             5,  7158,   486,     6,    40,  3094,     5,   403,   479, 50118,
          5341,    35,    83,  2470,    13,  1896,    18,   284,   161,    37,
          4265,     5,  3940,    40,   465, 22049,  2181,   479, 50118,   534,
         15356,  2459, 22049,   161,    79,  2215,     5, 28604,  2236,    16,
            14,     9,    69,   979,   479, 50118, 30541,     6, 41571,  1896,
            18, 18631,  1843,    26,    14,    24,    69,   979,    18,  2236,
            15,     5,  7158,   486,   479,     2]], device=&#39;cuda:0&#39;)


[[2]]
tensor([[ 1625,  4452,     7,    62,     7,   158,   135,     9,    70,   684,
          4707,    15,  3875,   479, 50118,   243,    16,   184,     7, 39179,
          3505,     9, 27772,     6, 28482,  5103,  4707,     8,   973,     6,
           151,  3505,     9,  3451,   479, 50118, 33837,   709,     8,  2147,
           464,    16,  9405,    10,   380,  8793,    15,    63, 28809,   479,
         50118,   133,  3274,  9587,    16,   223,  1856,    11, 14117,     9,
           145,     5,   247,    18,   632,  7648,   479,     2,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100],
        [ 5178,    35,    83,  1443,  2470,   161,    97,  1283,     6,    45,
             5,  7158,   486,     6,    40,  3094,     5,   403,   479, 50118,
          5341,    35,    83,  2470,    13,  1896,    18,   284,   161,    37,
          4265,     5,  3940,    40,   465, 22049,  2181,   479, 50118,   534,
         15356,  2459, 22049,   161,    79,  2215,     5, 28604,  2236,    16,
            14,     9,    69,   979,   479, 50118, 30541,     6, 41571,  1896,
            18, 18631,  1843,    26,    14,    24,    69,   979,    18,  2236,
            15,     5,  7158,   486,   479,     2]], device=&#39;cuda:0&#39;)</code></pre>
</div>
<div id="train" class="section level2">
<h2>Train</h2>
<p>Define a <code>Learner</code> object and train the model:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>text_gen_kwargs <span class="ot">=</span> hf_config<span class="sc">$</span>task_specific_params[<span class="st">&#39;summarization&#39;</span>][[<span class="dv">1</span>]]</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>text_gen_kwargs[<span class="st">&#39;max_length&#39;</span>] <span class="ot">=</span> 130L; text_gen_kwargs[<span class="st">&#39;min_length&#39;</span>] <span class="ot">=</span> 30L</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>text_gen_kwargs</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">HF_BaseModelWrapper</span>(hf_model)</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>model_cb <span class="ot">=</span> <span class="fu">HF_SummarizationModelCallback</span>(<span class="at">text_gen_kwargs=</span>text_gen_kwargs)</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>learn <span class="ot">=</span> <span class="fu">Learner</span>(dls,</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>                model,</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>                <span class="at">opt_func=</span><span class="fu">partial</span>(Adam),</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>                <span class="at">loss_func=</span><span class="fu">CrossEntropyLossFlat</span>(), <span class="co">#HF_PreCalculatedLoss()</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>                <span class="at">cbs=</span>model_cb,</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>                <span class="at">splitter=</span><span class="fu">partial</span>(summarization_splitter, <span class="at">arch=</span>hf_arch)) <span class="co">#.to_native_fp16() #.to_fp16()</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>learn<span class="sc">$</span><span class="fu">create_opt</span>()</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>learn<span class="sc">$</span><span class="fu">freeze</span>()</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>learn <span class="sc">%&gt;%</span> <span class="fu">fit_one_cycle</span>(<span class="dv">1</span>, <span class="at">lr_max=</span><span class="fl">4e-5</span>)</span></code></pre></div>
</div>
<div id="conclusion" class="section level2">
<h2>Conclusion</h2>
<p>Predict a new text:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>test_article <span class="ot">=</span> <span class="fu">c</span>(<span class="st">&quot;About 10 men armed with pistols and small machine guns raided a casino in Switzerland </span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="st">and made off into France with several hundred thousand Swiss francs in the early hours </span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="st">of Sunday morning, police said. The men, dressed in black clothes and black ski masks, </span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="st">split into two groups during the raid on the Grand Casino Basel, Chief Inspector Peter </span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="st">Gill told CNN. One group tried to break into the casino&#39;s vault on the lower level</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="st">but could not get in, but they did rob the cashier of the money that was not secured, </span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="st">he said. The second group of armed robbers entered the upper level where the roulette </span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="st">and blackjack tables are located and robbed the cashier there, he said. As the thieves </span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="st">were leaving the casino, a woman driving by and unaware of what was occurring unknowingly </span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a><span class="st">blocked the armed robbers&#39; vehicles. A gunman pulled the woman from her vehicle, beat</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a><span class="st">her, and took off for the French border. The other gunmen followed into France, which </span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a><span class="st">is only about 100 meters (yards) from the casino, Gill said. There were about 600 people </span></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a><span class="st">in the casino at the time of the robbery. There were no serious injuries, although one </span></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a><span class="st">guest on the Casino floor was kicked in the head by one of the robbers when he moved, </span></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a><span class="st">the police officer said. Swiss authorities are working closely with French authorities,</span></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a><span class="st">Gill said. The robbers spoke French and drove vehicles with French lRicense plates. </span></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a><span class="st">CNN&#39;s Andreena Narayan contributed to this report.&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>outputs <span class="ot">=</span> learn<span class="sc">$</span><span class="fu">blurr_summarize</span>(test_article, <span class="at">num_return_sequences=</span>3L)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(outputs)</span></code></pre></div>
<pre><code>
 Robbers made off with several hundred thousand Swiss francs in the early hours of Sunday morning, police say .
The men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino Basel .
There were no serious injuries, although one guest was kicked in the head by one of the robbers when he moved, police officer says .
A woman driving by unknowingly blocked the robbers&#39; vehicles and was beaten to death .
Swiss authorities are working closely with French authorities, police chief says .


 Robbers made off with several hundred thousand Swiss francs in the early hours of Sunday morning, police say .
The men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino Basel .
There were no serious injuries, although one guest was kicked in the head by one of the robbers when he moved, police officer says .
A woman driving by unknowingly blocked the robbers&#39; vehicles and was beaten to death .
Swiss authorities are working closely with French authorities, an officer says.


 Robbers made off with several hundred thousand Swiss francs in the early hours of Sunday morning, police say .
The men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino Basel .
There were no serious injuries, although one guest was kicked in the head by one of the robbers when he moved, police officer says .
A woman driving by unknowingly blocked the robbers&#39; vehicles and was beaten to death .</code></pre>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
